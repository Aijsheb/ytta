{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aijsheb/ytta/blob/main/Prak4_G_211_22_0020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "vf7fFzdC6rR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, RocCurveDisplay, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "XCpdmVmZ66d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0hc4rHhh7C9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing quick info about the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "iCJLlgUL7GNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values in each column\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "sltLmQBD7LeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify duplicate values and mark all the duplicates as true\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
        "\n",
        "df[df.duplicated (keep=False)]"
      ],
      "metadata": {
        "id": "-wd7UOsk7OzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
        "# drop data duplicated\n",
        "df = df.drop_duplicates (keep='first')"
      ],
      "metadata": {
        "id": "4aYZemzA7Rvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of the credit card fraud cases\n",
        "class_proportion = df['Class'].value_counts()\n",
        "class_proportion"
      ],
      "metadata": {
        "id": "eUmNv7AH7VH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a barchart to see the the distribution of the credit card fraud cases\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn')\n",
        "font1 = {'family': 'serif',\n",
        "         'fontstyle': 'italic',\n",
        "         'fontsize': 16,\n",
        "         'fontweight': 'bold',\n",
        "         'color': 'DarkBlue'}\n",
        "font2 = {'weight': 'bold', 'size': 12}\n",
        "font3 = {\"weight\":\"normal\", \"size\": 12}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.barplot(x=class_proportion.index, y=class_proportion.values, palette='Set2')\n",
        "ax.set_title('Distribution of Credit Card Fraud Class', fontdict=font1)\n",
        "ax.set_xlabel('Fraud class', fontdict=font2)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=8)\n",
        "ax.set_ylabel('Number of transactions', fontdict=font2)\n",
        "ax.set_yscale('log')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels=['e: Legitimate', '1: Fraudulent'], prop=font3,\n",
        "            title='Fraud Class:', title_fontsize=14,\n",
        "            frameon=True, facecolor=\"white\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aOeLyxyJ7Xd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the proportion of the fraud cases and identify the imbalance 2 df['class'].value_counts (normalize=True) |\n",
        "df['Class'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "aA1RWcY77bqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrange the dataset into features matrix and target vector\n",
        "# Drop the 'Time' variable as it does not that much help our analysis\n",
        "X = df.drop(columns=(['Time', 'Class']))\n",
        "y = df[ 'Class']"
      ],
      "metadata": {
        "id": "3rA15wiu7guK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a SMOTE instance, then fit and apply it in one step\n",
        "# to create an oversampled version of our dataset. 3\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE (sampling_strategy='auto', random_state=3, k_neighbors=5)\n",
        "X_oversampled, y_oversampled = sm.fit_resample(X, y)\n"
      ],
      "metadata": {
        "id": "oi4HiMjh7jq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the fraud class distribution of the new SMOTE-transformed dataset\n",
        "unique_original, counts_original = np.unique (y, return_counts=True)\n",
        "unique_oversampled, counts_oversampled = np. unique (y_oversampled, return_counts=True)\n",
        "\n",
        "print('Original fraud class distribution:', dict(zip(unique_original, counts_original)))\n",
        "print('New transformed fraud class distribution:',dict(zip(unique_oversampled, counts_oversampled)))\n"
      ],
      "metadata": {
        "id": "dY6H_q7f7mUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the SMOTE-transformed target variable\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "font1 = {'family': 'serif',\n",
        "         'fontstyle': 'italic',\n",
        "         'fontsize': 16,\n",
        "         'fontweight': 'bold',\n",
        "         'color': 'DarkBlue'}\n",
        "font2 = {'weight': 'bold', 'size': 12}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "sns.countplot(y_oversampled, palette='Set2', ax=ax)\n",
        "ax.set_title('Distribution of Imbalanced Fraud Class Transformed by SMOTE', fontdict=font1)\n",
        "ax.set_xlabel('Fraud class', fontdict=font2)\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_xticklabels(['Legitimate', 'Fraudulent'])\n",
        "\n",
        "ax.set_ylabel('Number of transactions', fontdict=font2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ueGnzFv87y-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Separate the transformed features matrix and target vector into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, random_state=3)"
      ],
      "metadata": {
        "id": "Y7RjcIlO749d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=150)\n",
        "rfc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rqxhckNF8ED2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evalution -classification accuracy\n",
        "training_rfc_accuracy = rfc.score (X_train, y_train)\n",
        "testing_rfc_accuracy = rfc.score (X_test, y_test)\n",
        "\n",
        "print(\"Training RFC Accuracy:\", training_rfc_accuracy)\n",
        "print(\"Testing RFC Accuracy:\", testing_rfc_accuracy )"
      ],
      "metadata": {
        "id": "TUmuYtir8F8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "font1 = {'family': 'serif',\n",
        "         'fontstyle': 'italic',\n",
        "         'fontsize': 16,\n",
        "         'fontweight': 'bold',\n",
        "         'color': 'DarkRed'}\n",
        "font2 = {'weight': 'bold', 'size': 12}\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, rfc.predict(X_test)),\n",
        "            cmap='Blues',\n",
        "            square=True,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cbar_kws={'shrink': 0.8},\n",
        "            xticklabels=['Predicted es', 'Predicted 1s'],\n",
        "            yticklabels=['Actual es', 'Actual is'])\n",
        "ax.set_title('RFC Confusion Matrix', fontdict=font1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iHALpRAs8I48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation - Sensitivity, Specificity and Precision\n",
        "\n",
        "TN, FP, FN, TP = confusion_matrix(y_test, rfc.predict(X_test)). flatten()\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"False Negatives:\", FN)\n",
        "print(\"True Positives:\", TP)\n",
        "\n",
        "sensitivity = TP/(TP + FN)\n",
        "specificity = TN/(TN+FP)\n",
        "precision = TP/(TP + FP)\n",
        "print(\"\\nSensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "DyKqgR508MHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the predicted probabilities for every observation in the test data subset\n",
        "# Note that the default classification threshold is 0.5\n",
        "\n",
        "testing_probabilities= rfc.predict_proba(X_test)\n",
        "testing_probabilities"
      ],
      "metadata": {
        "id": "a72bUXaO8PQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the testing probabilities into a dataframe\n",
        "testing_probabilities_df = pd.DataFrame(testing_probabilities, columns=['1 - p(x_test)', 'p(x_test)'])\n",
        "testing_probabilities_df.head()"
      ],
      "metadata": {
        "id": "4eD0uUeu8RmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "gW0f6-8i8Uwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation -AUC\n",
        "# Calculate AUC for both training and testing subsets\n",
        "# Only probabilities being in the positive class is needed for the calculation, that is the second column\n",
        "training_rfc_AUC = roc_auc_score (y_train, rfc.predict_proba (X_train) [:, 1])\n",
        "testing_rfc_AUC = roc_auc_score (y_test, rfc.predict_proba (X_test) [:, 1])\n",
        "\n",
        "print(\"Training RFC AUC:\", training_rfc_AUC)\n",
        "print(\"Testing RFC AUC:\", testing_rfc_AUC)"
      ],
      "metadata": {
        "id": "_-n2Ykxw8o8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the transformed features matrix and target vector into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, random_state=3)"
      ],
      "metadata": {
        "id": "fKx-RqEb8vff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'penalty': ['l1', 'l2'],  # Menggunakan 'l1' dan 'l2' sebagai opsi penalty\n",
        "          'C': [0.0001, 0.001, 0.01, 10, 50, 100],\n",
        "          'class_weight': [None, 'balanced']}\n",
        "# Instantiate Logistic Regression model. N.8: the default solver doesn't support 11 regularization\n",
        "# Instantiate Grid Search to find the best hyperparameters and fit the model\n",
        "lgr = LogisticRegression(solver='liblinear')\n",
        "gs = GridSearchCV(lgr, params, cv=5)\n",
        "gs.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vKXCkz0Z8wDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation - accuracy\n",
        "training_lgr_accuracy = gs.score (X_train, y_train)\n",
        "testing_lgr_accuracy = gs.score (X_test, y_test)\n",
        "\n",
        "print(\"Training LGR Accuracy:\", training_lgr_accuracy)\n",
        "print(\"Testing LGR Accuracy:\", testing_lgr_accuracy)"
      ],
      "metadata": {
        "id": "a-jBwDdm8wHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "font1 = {'family': 'serif',\n",
        "         'fontstyle': 'italic',\n",
        "         'fontsize': 16,\n",
        "         'fontweight': 'bold',\n",
        "         'color': 'DarkRed'}\n",
        "\n",
        "ConfusionMatrixDisplay(gs, X_test, y_test, values_format=\"d\")\n",
        "plt.title('LGR Confusion Matrix', fontdict=font1)\n",
        "plt.grid(False)\n",
        "plt.show()# Model evaluation - Sensitivity, Specificity and Precision\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"True Negatives:\", 69349)\n",
        "print(\"False Positives:\", 1279)\n",
        "print(\"False Negatives:\", 4710)\n",
        "print(\"True Positives:\", 66289)\n",
        "\n",
        "sensitivity = 0,9336610374794011\n",
        "specificity = 0,9818910347171094\n",
        "precision = 0.9810709211461036\n",
        "print(\"\\nSensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "id": "ST-pTcZJ83zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation -AUC\n",
        "# Calculate AUC for both training and testing subsets\n",
        "# Only probabilities being in the positive class is needed for the calculation, that is the second column\n",
        "training_lgr_AUC = 0,9918803796502905\n",
        "training_lgr_AUC = 0,9915963855793377\n",
        "\n",
        "print(\"Training LGR AUC:\",training_lgr_AUC)"
      ],
      "metadata": {
        "id": "z-EB5xRq837E",
        "outputId": "0b744cee-a5b7-4f46-8859-c5690885ac59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LGR AUC: (0, 9915963855793377)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}